{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c62e593-e24e-4989-b141-da59a20c8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ad904c-a3ca-4f7c-b792-94b40af0c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf3335a-2a1b-4039-b85d-a78d912134ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2995 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"tomatoImages\",\n",
    "    shuffle = True,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7bcece-61d8-4ea6-8cf9-cbc41c676dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tomato__Target_Spot', 'Tomato_healthy']\n"
     ]
    }
   ],
   "source": [
    "names  = dataset.class_names\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0661a3b0-447f-4941-9621-40df25c892bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_train_spilit(dataset, train_size = 0.8, test_size = 0.1, val_size = 0.1, shuffle = True, shuffle_size = 10000):\n",
    "#     ds_size = len(dataset)\n",
    "\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(shuffle_size, seed = 12)\n",
    "\n",
    "#     train_ds = dataset.take(int(ds_size*train_size))\n",
    "#     val_ds = dataset.skip(int(ds_size*train_size)).take(int(ds_size*val_size))\n",
    "#     test_ds = dataset.skip(int(ds_size*train_size)).skip(int(ds_size*val_size))\n",
    "                \n",
    "#     return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ae4579-859a-4440-9c43-a2ac5f090f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to make the result closer to the \"Morgh\" project.\n",
    "# otherwise the 'test_train_spilit' function can be used.\n",
    "def split_dataset_by_count(dataset, train_count , val_count , test_count, shuffle_size=10000, seed=12):\n",
    "    \"\"\"\n",
    "    Shuffles, subsets, and splits a tf.data.Dataset by absolute counts.\n",
    "    \"\"\"\n",
    "    dataset = dataset.shuffle(shuffle_size, seed=seed)\n",
    "    \n",
    "    dataset = dataset.unbatch()\n",
    "    \n",
    "    total_count = train_count + val_count + test_count\n",
    "    subset_ds = dataset.take(total_count)\n",
    "    \n",
    "    train_ds = subset_ds.take(train_count)\n",
    "    val_ds = subset_ds.skip(train_count).take(val_count)\n",
    "    test_ds = subset_ds.skip(train_count + val_count).take(test_count)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4caf19c0-278c-459b-814f-0bf2b72af744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = split_dataset_by_count(dataset, \n",
    "                                                   train_count=200, \n",
    "                                                   val_count=20, \n",
    "                                                   test_count=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3889fad3-7e9e-4725-8a07-b94aa38ae765",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The dataset length is unknown.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mlen\u001b[39m(val_ds), \u001b[38;5;28mlen\u001b[39m(test_ds))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\azin\\tomato\\code\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:533\u001b[39m, in \u001b[36mDatasetV2.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    531\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe dataset is infinite.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length.numpy() == UNKNOWN:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe dataset length is unknown.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m length\n",
      "\u001b[31mTypeError\u001b[39m: The dataset length is unknown."
     ]
    }
   ],
   "source": [
    "# print(len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e51bdf87-afee-4ebc-86c8-2bde4c250aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ec7a61-a073-4af7-a11d-ed49db504aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.keras.Sequential([\n",
    "    layers.Resizing(IMG_SIZE,IMG_SIZE),\n",
    "])\n",
    "# rescaling is not needed due to resnet50 preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df673ac-0795-43c6-a88e-93aa9674926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation =  tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizantal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac13373c-b1b7-4f90-8ea0-4f1e4d0856a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "NUM_CLASSES = len(names)\n",
    "\n",
    "resnet_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE\n",
    ")\n",
    "\n",
    "resnet_model.trainable = False\n",
    "\n",
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35f893ed-8374-4012-821c-c180ded95666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\azin\\tomato\\code\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py:65: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    resize, \n",
    "    data_augmentation,\n",
    "    layers.Lambda(preprocess_input, input_shape=INPUT_SHAPE),\n",
    "    resnet_model,\n",
    "    layers.GlobalAveragePooling2D(), \n",
    "\n",
    "    layers.Dense(128, activation='relu'), \n",
    "    layers.Dropout(0.2), \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2), \n",
    "\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4845e82-fdb3-4f5d-9131-5199f5b86f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29958f3e-977e-431e-a8d2-083169643ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\azin\\tomato\\code\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "      7/Unknown \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.5987 - loss: 0.8056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\azin\\tomato\\code\\venv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.6350 - loss: 0.7060 - val_accuracy: 0.7500 - val_loss: 0.4718\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7050 - loss: 0.5906 - val_accuracy: 0.9500 - val_loss: 0.2244\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7650 - loss: 0.4407 - val_accuracy: 0.9000 - val_loss: 0.2673\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9000 - loss: 0.2749 - val_accuracy: 1.0000 - val_loss: 0.1145\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9050 - loss: 0.2278 - val_accuracy: 1.0000 - val_loss: 0.1193\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9300 - loss: 0.1288 - val_accuracy: 1.0000 - val_loss: 0.0658\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9500 - loss: 0.1157 - val_accuracy: 1.0000 - val_loss: 0.0884\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9600 - loss: 0.1031 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9550 - loss: 0.1047 - val_accuracy: 1.0000 - val_loss: 0.0996\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9850 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs =  EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    verbose = 1,\n",
    "    validation_data = val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4f99209-b919-4ab9-ac8c-ce4490b3dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.trainable = True\n",
    "\n",
    "for layer in resnet_model.layers[:-30]: # Fine-tune top 30 layers, adjust as needed\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72dcaa78-4339-430f-b94d-e76328dd54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0445325-aa99-4567-9f76-09c6ddcd444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = 10 + fine_tune_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc8d15c-b2ae-4f44-8b0c-2d18795ae274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.8150 - loss: 0.4038 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.8950 - loss: 0.2357 - val_accuracy: 1.0000 - val_loss: 0.0507\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9600 - loss: 0.1063 - val_accuracy: 1.0000 - val_loss: 0.0818\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9700 - loss: 0.0881 - val_accuracy: 0.9000 - val_loss: 0.1229\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9800 - loss: 0.0551 - val_accuracy: 0.9000 - val_loss: 0.1527\n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9700 - loss: 0.0759 - val_accuracy: 0.9000 - val_loss: 0.1556\n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9950 - loss: 0.0336 - val_accuracy: 0.9000 - val_loss: 0.1481\n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9900 - loss: 0.0476 - val_accuracy: 0.9000 - val_loss: 0.1233\n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9700 - loss: 0.0628 - val_accuracy: 0.9500 - val_loss: 0.0944\n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9800 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.0680\n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9800 - loss: 0.0498 - val_accuracy: 1.0000 - val_loss: 0.0638\n"
     ]
    }
   ],
   "source": [
    "history_fine_tune = model.fit(\n",
    "    train_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1], \n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb2522e3-f661-43a6-8fc1-5f8f5c401605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 614ms/step - accuracy: 0.8250 - loss: 0.2942\n"
     ]
    }
   ],
   "source": [
    "scores  = model.evaluate(test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80197dd6-133c-411a-9104-2ecc7cab9d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
